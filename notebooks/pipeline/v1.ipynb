{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2069746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torchaudio                   # type: ignore\n",
    "\n",
    "root = os.path.expanduser(\"~/.cache\")\n",
    "\n",
    "ds = torchaudio.datasets.LIBRISPEECH(root=root, url=\"test-clean\", download=True)\n",
    "\n",
    "audio, sr, text, *_ = ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed5b2791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' He hoped there would be stew for dinner, turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out in thick, peppered flour-fatten sauce.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "waveform = audio.squeeze().numpy()\n",
    "\n",
    "result = model.transcribe(waveform, fp16=False)\n",
    "\n",
    "result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "062d8976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He eagerly anticipated a hearty homemade stew as the main course of his meal. He envisioned chunks of tender turnips simmering alongside earthy carrots and potatoes that had seen better days but still possessed flavorful depth due to their slight bruising, all complemented by rich mutton pieces generously cooked in a velvety sauce thickened with pepper-infused flour. The dish promised warmth not just for his belly but also an invigorating experience that connected him back to traditional comfort foods of the past.\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat                 # type: ignore\n",
    "from ollama import ChatResponse         # type: ignore\n",
    "\n",
    "system_prompt = \"You are a helpful, polite, and clear assistant in all your responses.\"\n",
    "\n",
    "response: ChatResponse = chat(model='phi3:instruct', messages=[\n",
    "    { \"role\": \"system\", \"content\": system_prompt },\n",
    "    { 'role': 'user', 'content': result[\"text\"] },\n",
    "])\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45d938f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_prompt = response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5f44fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BarkModel, AutoProcessor\n",
    "import torch\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "model = BarkModel.from_pretrained(\"suno/bark-small\").to(device)\n",
    "processor = AutoProcessor.from_pretrained(\"suno/bark\")\n",
    "\n",
    "inputs = processor(text_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    speech_output = model.generate(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2462bbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wav\n",
    "\n",
    "audio = speech_output.cpu().numpy().squeeze()\n",
    "wav.write(\"output.wav\", model.generation_config.sample_rate, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "380fa971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='output.mp3'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "AudioSegment.from_wav(\"output.wav\").export(\"output.mp3\", format=\"mp3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "talker-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
