{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "748c2b18",
   "metadata": {},
   "source": [
    "https://pypi.org/project/openai-whisper/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f92f05",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/github/openai/whisper/blob/master/notebooks/LibriSpeech.ipynb#scrollTo=3CqtR2Fi5-vP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8560e97b",
   "metadata": {},
   "source": [
    "Installing Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1474c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install jiwer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee7e4a4",
   "metadata": {},
   "source": [
    "Loading the LibriSpeech dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd65cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import tensorflow  # required in Colab to avoid protobuf compatibility issues\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import whisper\n",
    "import torchaudio\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4de49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LibriSpeech(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A simple class to wrap LibriSpeech and trim/pad the audio to 30 seconds.\n",
    "    It will drop the last few seconds of a very small portion of the utterances.\n",
    "    \"\"\"\n",
    "    def __init__(self, split=\"test-clean\", device=DEVICE):\n",
    "        self.dataset = torchaudio.datasets.LIBRISPEECH(\n",
    "            root=os.path.expanduser(\"~/.cache\"),\n",
    "            url=split,\n",
    "            download=True,\n",
    "        )\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        audio, sample_rate, text, _, _, _ = self.dataset[item]\n",
    "        assert sample_rate == 16000\n",
    "        audio = whisper.pad_or_trim(audio.flatten()).to(self.device)\n",
    "        mel = whisper.log_mel_spectrogram(audio)\n",
    "        \n",
    "        return (mel, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3c879e",
   "metadata": {},
   "source": [
    "Running inference on the dataset using a base Whisper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b662f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LibriSpeech(\"test-clean\")\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d749ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base.en\")\n",
    "print(\n",
    "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
    "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a05081",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = whisper.DecodingOptions(language=\"en\", without_timestamps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f593b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses = []\n",
    "references = []\n",
    "\n",
    "for mels, texts in tqdm(loader):\n",
    "    results = model.decode(mels, options)\n",
    "    hypotheses.extend([result.text for result in results])\n",
    "    references.extend(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5324d7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8752680c",
   "metadata": {},
   "source": [
    "Calculating the word error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d883fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiwer                            # type: ignore\n",
    "from whisper.normalizers import EnglishTextNormalizer\n",
    "\n",
    "normalizer = EnglishTextNormalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b289e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"hypothesis_clean\"] = [normalizer(text) for text in data[\"hypothesis\"]]\n",
    "data[\"reference_clean\"] = [normalizer(text) for text in data[\"reference\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35379981",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer = jiwer.wer(list(data[\"reference_clean\"]), list(data[\"hypothesis_clean\"]))\n",
    "\n",
    "print(f\"WER: {wer * 100:.2f} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "talker-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
